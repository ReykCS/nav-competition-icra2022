<?xml version="1.0" encoding="UTF-8"?>
<launch>

  <!-- Arguments -->
  <arg name="model" default="turtlebot3_burger"/>
  <arg name="cmd_vel_topic" default="cmd_vel" />
  <arg name="odom_topic" default="odom" />
  <arg name="agent_name" default="jackal"/>
  <arg name="use_rviz" default="true"/>
  <arg name="trainings_environment" default="rosnav" />
  <arg name="goal_x" default="0" />
  <arg name="goal_y" default="0" />
  <arg name="goal_z" default="0" />

  <param name="bool_goal_reached" value="true"/>
  <param name="action_frequency" value="5" />


  <!-- move_base -->
  <node pkg="move_base" type="move_base" respawn="false" name="move_base" output="screen">
    <rosparam file="$(find jackal_helper)/configs/params/costmap_common_params.yaml" command="load" ns="global_costmap" />
    <rosparam file="$(find jackal_helper)/configs/params/costmap_common_params.yaml" command="load" ns="local_costmap" />   
    
    <rosparam file="$(find jackal_helper)/configs/params/odom_nav_params/local_costmap_params.yaml" command="load" />
    <rosparam file="$(find jackal_helper)/configs/params/odom_nav_params/global_costmap_params.yaml" command="load" />
  
    <remap from="cmd_vel" to="tmp/cmd_vel" />
  </node>

  <!-- AMCL -->
  <!-- <include file="$(find arena_bringup)/launch/amcl.launch">
    <arg name="drl" value="true"/>
  </include> -->

  <!-- spacial_horizon -->
  <node pkg="arena_spacial_horizon" type="spacial_horizon_node" name="spacial_horizon_node" output="screen">
    <rosparam file="$(find arena_spacial_horizon)/plan_fsm_param.yaml" command="load" /> <!-- ns="fsm"-->
  </node>

  <!-- scan mapping, because training and real scan calibration may differ
  <include file="$(find arena_bringup)/launch/map_scan.launch">
  </include> -->

  <!-- observation_packer- to compare calculated distances from robot to goal -->
  <!-- <node pkg="observations" name="observation_packer" type="observation_packer" output="screen"/> -->

  <node
    name="goal_publisher"
    pkg="arena_local_planner_drl"
    type="goal_publisher.py"
    args="-x $(arg goal_x) -y $(arg goal_y) -z $(arg goal_z)"
  />

  <!-- run_agent -->
  <node 
    name="drl_local_planner" 
    pkg="arena_local_planner_drl" 
    type="drl_agent_node.py" 
    args="$(arg agent_name)"
    output="screen"
  />

  <!-- action_publisher -->
  <!-- makes sure that drl actions will be published according to sim time in eval mode-->
  <!-- <node name="action_publisher" pkg="arena_local_planner_drl" type="action_publisher.py"/> -->

</launch>